{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignorar warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np #operaciones matriciales y con vectores\n",
    "import pandas as pd #tratamiento de datos\n",
    "import matplotlib.pyplot as plt #gráficos\n",
    "from sklearn import metrics, tree\n",
    "from sklearn.model_selection import cross_val_score, cross_validate #método para evaluar varios particionamientos de C-V\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "#Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Boosting\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import zero_one_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case1_Control0</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Genero</th>\n",
       "      <th>Cycle Time</th>\n",
       "      <th>Stance Percent</th>\n",
       "      <th>Stance Time</th>\n",
       "      <th>Step Length</th>\n",
       "      <th>Step Number</th>\n",
       "      <th>Step Time</th>\n",
       "      <th>Step Cadence</th>\n",
       "      <th>...</th>\n",
       "      <th>Step Timel</th>\n",
       "      <th>Step Cadencel</th>\n",
       "      <th>Stride Numberl</th>\n",
       "      <th>Stride Lengthl</th>\n",
       "      <th>Swing Percentl</th>\n",
       "      <th>Swing Timel</th>\n",
       "      <th>Distancel</th>\n",
       "      <th>Duration Timel</th>\n",
       "      <th>Speedl</th>\n",
       "      <th>Accelerationl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positivo</td>\n",
       "      <td>79</td>\n",
       "      <td>M</td>\n",
       "      <td>0.803979</td>\n",
       "      <td>0.644524</td>\n",
       "      <td>1.327075</td>\n",
       "      <td>0.796338</td>\n",
       "      <td>2</td>\n",
       "      <td>0.335486</td>\n",
       "      <td>58.280750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312041</td>\n",
       "      <td>88.428185</td>\n",
       "      <td>1</td>\n",
       "      <td>0.185463</td>\n",
       "      <td>0.459888</td>\n",
       "      <td>0.624083</td>\n",
       "      <td>1.890646</td>\n",
       "      <td>1.357033</td>\n",
       "      <td>1.393220</td>\n",
       "      <td>1.026666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positivo</td>\n",
       "      <td>79</td>\n",
       "      <td>M</td>\n",
       "      <td>0.826989</td>\n",
       "      <td>0.633677</td>\n",
       "      <td>1.326004</td>\n",
       "      <td>0.823259</td>\n",
       "      <td>2</td>\n",
       "      <td>0.352115</td>\n",
       "      <td>57.346196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429035</td>\n",
       "      <td>59.169468</td>\n",
       "      <td>1</td>\n",
       "      <td>1.198056</td>\n",
       "      <td>0.423096</td>\n",
       "      <td>0.858070</td>\n",
       "      <td>1.923441</td>\n",
       "      <td>2.028073</td>\n",
       "      <td>0.948408</td>\n",
       "      <td>0.467640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positivo</td>\n",
       "      <td>79</td>\n",
       "      <td>M</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>0.610778</td>\n",
       "      <td>1.219237</td>\n",
       "      <td>0.739892</td>\n",
       "      <td>2</td>\n",
       "      <td>0.359121</td>\n",
       "      <td>60.114133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405821</td>\n",
       "      <td>56.550877</td>\n",
       "      <td>1</td>\n",
       "      <td>1.059078</td>\n",
       "      <td>0.382493</td>\n",
       "      <td>0.811643</td>\n",
       "      <td>1.974094</td>\n",
       "      <td>2.121983</td>\n",
       "      <td>0.930306</td>\n",
       "      <td>0.438414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positivo</td>\n",
       "      <td>68</td>\n",
       "      <td>M</td>\n",
       "      <td>1.193026</td>\n",
       "      <td>0.536687</td>\n",
       "      <td>1.263887</td>\n",
       "      <td>0.741654</td>\n",
       "      <td>2</td>\n",
       "      <td>0.476885</td>\n",
       "      <td>50.955888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435792</td>\n",
       "      <td>50.936203</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085094</td>\n",
       "      <td>0.369960</td>\n",
       "      <td>0.871583</td>\n",
       "      <td>1.951583</td>\n",
       "      <td>2.355888</td>\n",
       "      <td>0.828385</td>\n",
       "      <td>0.351623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positivo</td>\n",
       "      <td>68</td>\n",
       "      <td>M</td>\n",
       "      <td>1.045567</td>\n",
       "      <td>0.508093</td>\n",
       "      <td>1.061983</td>\n",
       "      <td>0.817604</td>\n",
       "      <td>2</td>\n",
       "      <td>0.446011</td>\n",
       "      <td>57.412502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358499</td>\n",
       "      <td>59.642470</td>\n",
       "      <td>1</td>\n",
       "      <td>1.189026</td>\n",
       "      <td>0.356362</td>\n",
       "      <td>0.716997</td>\n",
       "      <td>1.858186</td>\n",
       "      <td>2.011989</td>\n",
       "      <td>0.923557</td>\n",
       "      <td>0.459027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case1_Control0  Edad Genero  Cycle Time  Stance Percent  Stance Time  \\\n",
       "0       Positivo    79      M    0.803979        0.644524     1.327075   \n",
       "1       Positivo    79      M    0.826989        0.633677     1.326004   \n",
       "2       Positivo    79      M    0.789131        0.610778     1.219237   \n",
       "3       Positivo    68      M    1.193026        0.536687     1.263887   \n",
       "4       Positivo    68      M    1.045567        0.508093     1.061983   \n",
       "\n",
       "   Step Length  Step Number  Step Time  Step Cadence      ...        \\\n",
       "0     0.796338            2   0.335486     58.280750      ...         \n",
       "1     0.823259            2   0.352115     57.346196      ...         \n",
       "2     0.739892            2   0.359121     60.114133      ...         \n",
       "3     0.741654            2   0.476885     50.955888      ...         \n",
       "4     0.817604            2   0.446011     57.412502      ...         \n",
       "\n",
       "   Step Timel  Step Cadencel  Stride Numberl  Stride Lengthl  Swing Percentl  \\\n",
       "0    0.312041      88.428185               1        0.185463        0.459888   \n",
       "1    0.429035      59.169468               1        1.198056        0.423096   \n",
       "2    0.405821      56.550877               1        1.059078        0.382493   \n",
       "3    0.435792      50.936203               1        1.085094        0.369960   \n",
       "4    0.358499      59.642470               1        1.189026        0.356362   \n",
       "\n",
       "   Swing Timel  Distancel  Duration Timel    Speedl  Accelerationl  \n",
       "0     0.624083   1.890646        1.357033  1.393220       1.026666  \n",
       "1     0.858070   1.923441        2.028073  0.948408       0.467640  \n",
       "2     0.811643   1.974094        2.121983  0.930306       0.438414  \n",
       "3     0.871583   1.951583        2.355888  0.828385       0.351623  \n",
       "4     0.716997   1.858186        2.011989  0.923557       0.459027  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_set_cleaned.csv', header = 0, names=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.loc[: , ~data.columns.isin(['Case1_Control0'])]\n",
    "x = pd.get_dummies(data=x)\n",
    "x = x.values\n",
    "\n",
    "y = data['Case1_Control0'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning\n",
    "\n",
    "Se buscan los mejores parametros de encontrar el mejor desempeño de los modelos basados en arboles de decisión y validando los resultados usando 10-CV para evitar el overfit:\n",
    "\n",
    "#### Bagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parametros:\n",
      " {'base_estimator__max_depth': 10, 'base_estimator__min_samples_split': 5, 'max_features': 0.7, 'max_samples': 0.05, 'n_estimators': 50}\n",
      "Mejor Exactitud:\n",
      " 0.7087912087912088\n"
     ]
    }
   ],
   "source": [
    "#Tunear modelo Bagging\n",
    "\n",
    "#Parametros a tunear\n",
    "param_grid = {\n",
    "    'base_estimator__max_depth' : [2, 5, 10, 200],\n",
    "    'base_estimator__min_samples_split' : [5,10,20],\n",
    "    'n_estimators' : [10, 50, 100, 200],\n",
    "    'max_samples' : [0.05, 0.2, 0.5, 0.7],\n",
    "    'max_features' : [0.05, 0.2, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "GS_BT = GridSearchCV(BaggingClassifier(tree.DecisionTreeClassifier()),\n",
    "                     param_grid=param_grid, scoring='accuracy', cv=10)\n",
    "\n",
    "GS_BT.fit(x, y)\n",
    "\n",
    "print('Mejores parametros:\\n', GS_BT.best_params_)\n",
    "print('Mejor Exactitud:\\n', GS_BT.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mejores parametros:**  \n",
    " {'base_estimator__max_depth': 10, 'base_estimator__min_samples_split': 5, 'max_features': 0.7, 'max_samples': 0.05, 'n_estimators': 50}  \n",
    "**Mejor Exactitud:**  \n",
    " 0.7087912087912088"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parametros:\n",
      " {'max_depth': 8, 'min_impurity_decrease': 0.1, 'min_samples_leaf': 1, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "Mejor Exactitud:\n",
      " 0.6758241758241759\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [10, 20, 40, 100],\n",
    "    'max_depth' : [8, 10],\n",
    "    'min_samples_split' : [10, 20, 25],\n",
    "    'min_samples_leaf' : [1, 5, 8, 10],\n",
    "    'min_impurity_decrease' : [0.0, 0.1]\n",
    "}\n",
    "\n",
    "GS_RF = GridSearchCV(RandomForestClassifier(criterion='entropy', max_features=('auto'),\n",
    "                                            bootstrap=True, oob_score=True,\n",
    "                                            random_state=1234, n_jobs=2, verbose=0),\n",
    "                     param_grid=param_grid, scoring='accuracy', cv=10)\n",
    "\n",
    "GS_RF.fit(x,y)\n",
    "\n",
    "print('Mejores parametros:\\n', GS_RF.best_params_)\n",
    "print('Mejor Exactitud:\\n', GS_RF.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mejores parametros:**  \n",
    " {'max_depth': 8, 'min_impurity_decrease': 0.1, 'min_samples_leaf': 1, 'min_samples_split': 20, 'n_estimators': 100}  \n",
    "**Mejor Exactitud:**  \n",
    " 0.6758241758241759"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parametros:\n",
      " {'max_depth': 12, 'min_impurity_decrease': 0.06221087710398319, 'min_samples_leaf': 16, 'min_samples_split': 13, 'n_estimators': 95}\n",
      "Mejor Exactitud:\n",
      " 0.6703296703296703\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators' : [randint.rvs(10,120,1)],\n",
    "    'max_depth' : [randint.rvs(5,15,1)],\n",
    "    'min_samples_split' : [randint.rvs(10,25,1)],\n",
    "    'min_samples_leaf' : [randint.rvs(1,20,1)],\n",
    "    'min_impurity_decrease' : uniform(0.0,0.1)\n",
    "}\n",
    "\n",
    "RS_RF = RandomizedSearchCV(RandomForestClassifier(criterion='entropy', max_features=('auto'),\n",
    "                                            bootstrap=True, oob_score=True,\n",
    "                                            random_state=1234, n_jobs=1, verbose=0), \n",
    "                           param_distributions=param_grid, scoring='accuracy', cv=10, random_state=1234)  \n",
    "\n",
    "RS_RF.fit(x,y)\n",
    "\n",
    "print('Mejores parametros:\\n', RS_RF.best_params_)\n",
    "print('Mejor Exactitud:\\n', RS_RF.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mejores parametros:**  \n",
    " {'max_depth': 12, 'min_impurity_decrease': 0.06221087710398319, 'min_samples_leaf': 16, 'min_samples_split': 13, 'n_estimators': 95}  \n",
    "**Mejor Exactitud:**  \n",
    " 0.6703296703296703"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting (Adaptive Boosting)\n",
    "\n",
    "Debido a que este modelo obtuvo un buen desempeño con el data set inicial, se usa posteriormente el dataset sin eliminar las anomalias, para explorar si los datos anomalos ayudar a discriminar los pacientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parametros:\n",
      " {'learning_rate': 0.05, 'n_estimators': 10}\n",
      "Mejor Exactitud:\n",
      " 0.7252747252747253\n"
     ]
    }
   ],
   "source": [
    "# Boosting\n",
    "\n",
    "param_grid ={\n",
    "    'n_estimators' : [10, 20, 100, 400],\n",
    "    'learning_rate' : [0.05, 0.1, 0.2, 0.5,0.7,0.8]\n",
    "}\n",
    "\n",
    "GS_Boo = GridSearchCV(AdaBoostClassifier(base_estimator=None, algorithm='SAMME'), \n",
    "                      param_grid=param_grid, scoring='accuracy', cv=10)\n",
    "GS_Boo.fit(x,y)\n",
    "\n",
    "print('Mejores parametros:\\n', GS_Boo.best_params_)\n",
    "print('Mejor Exactitud:\\n', GS_Boo.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mejores parametros:**  \n",
    " {'learning_rate': 0.05, 'n_estimators': 10}   \n",
    "**Mejor Exactitud:**  \n",
    " 0.7252747252747253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a = pd.read_csv('data_set_with_anomalys.csv', header = 0, names=None)\n",
    "data_a.head()\n",
    "\n",
    "xa = data_a.loc[: , ~data_a.columns.isin(['Case1_Control0'])]\n",
    "xa = pd.get_dummies(data=xa)\n",
    "xa = xa.values\n",
    "\n",
    "ya = data_a['Case1_Control0'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parametros:\n",
      " {'learning_rate': 0.05, 'n_estimators': 10}\n",
      "Mejor Exactitud:\n",
      " 0.7252747252747253\n"
     ]
    }
   ],
   "source": [
    "# Boosting with anomalys\n",
    "\n",
    "param_grid ={\n",
    "    'n_estimators' : [10, 20, 100, 400],\n",
    "    'learning_rate' : [0.05, 0.1, 0.2, 0.5,0.7,0.8]\n",
    "}\n",
    "\n",
    "GS_Boo = GridSearchCV(AdaBoostClassifier(base_estimator=None, algorithm='SAMME'), \n",
    "                      param_grid=param_grid, scoring='accuracy', cv=10)\n",
    "GS_Boo.fit(xa,ya)\n",
    "\n",
    "print('Mejores parametros:\\n', GS_Boo.best_params_)\n",
    "print('Mejor Exactitud:\\n', GS_Boo.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mejores parametros:**  \n",
    " {'learning_rate': 0.05, 'n_estimators': 10}  \n",
    "**Mejor Exactitud:**  \n",
    " 0.7252747252747253 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteristicas seleccionadas: Index(['Cycle Timel', 'Step Timel'], dtype='object')\n",
      "Mejor Exactitud: 0.7266081871345029\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=20, learning_rate=0.05, algorithm='SAMME', base_estimator=None)\n",
    "\n",
    "rfecv = RFECV(estimator=ada, step=1, cv=10, scoring='accuracy')\n",
    "\n",
    "rfecv.fit(x,y)\n",
    "\n",
    "print(\"Caracteristicas seleccionadas:\",data.columns[rfecv.support_])\n",
    "print(\"Mejor Exactitud:\", np.max(rfecv.grid_scores_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caracteristicas seleccionadas: Index(['Cycle Timel', 'Step Timel'], dtype='object')  \n",
    "Mejor Exactitud: 0.7266081871345029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteristicas seleccionadas: Index(['Case1_Control0', 'Edad', 'Genero', 'Cycle Time', 'Stance Percent',\n",
      "       'Stance Time', 'Step Length', 'Step Number', 'Step Time',\n",
      "       'Step Cadence', 'Stride Number', 'Stride Length', 'Swing Percent',\n",
      "       'Swing Time', 'Distance', 'Duration Time', 'Speed', 'Acceleration',\n",
      "       'Cycle Timel', 'Stance Percentl', 'Stance Timel', 'Step Lengthl',\n",
      "       'Step Numberl', 'Step Timel', 'Step Cadencel', 'Stride Numberl',\n",
      "       'Stride Lengthl', 'Swing Percentl', 'Swing Timel', 'Distancel',\n",
      "       'Duration Timel', 'Speedl', 'Accelerationl'],\n",
      "      dtype='object')\n",
      "Mejor Exactitud: 0.7266081871345029\n"
     ]
    }
   ],
   "source": [
    "# RFE with anomalys\n",
    "ada = AdaBoostClassifier(n_estimators=10, learning_rate=0.05, algorithm='SAMME', base_estimator=None)\n",
    "\n",
    "rfecv = RFECV(estimator=ada, step=1, cv=10, scoring='accuracy')\n",
    "\n",
    "rfecv.fit(xa,ya)\n",
    "\n",
    "print(\"Caracteristicas seleccionadas:\",data.columns[rfecv.support_])\n",
    "print(\"Mejor Exactitud:\",  np.max(rfecv.grid_scores_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caracteristicas seleccionadas:**   \n",
    "Index(['Case1_Control0', 'Edad', 'Genero', 'Cycle Time', 'Stance Percent',\n",
    "       'Stance Time', 'Step Length', 'Step Number', 'Step Time',\n",
    "       'Step Cadence', 'Stride Number', 'Stride Length', 'Swing Percent',\n",
    "       'Swing Time', 'Distance', 'Duration Time', 'Speed', 'Acceleration',\n",
    "       'Cycle Timel', 'Stance Percentl', 'Stance Timel', 'Step Lengthl',\n",
    "       'Step Numberl', 'Step Timel', 'Step Cadencel', 'Stride Numberl',\n",
    "       'Stride Lengthl', 'Swing Percentl', 'Swing Timel', 'Distancel',\n",
    "       'Duration Timel', 'Speedl', 'Accelerationl'],\n",
    "      dtype='object')  \n",
    "**Mejor Exactitud:**  \n",
    "0.7266081871345029"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el procedimiento RFE, se logra mejorar el desempeño de ambos dataset (limpio y original), pero, el dataset sin los datos anomalos logró mejorar la exactitud con solo dos caracteristicas (Columnas), mientras que el dataset original requiere de casi todas las columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de metricas del modelo seleccionado (Mejor exactitud)\n",
    "\n",
    "Métricas:\n",
    "- **Accuracy:** porcentaje de personas bien clasificadas (TP y TF) de todos las personas. Esta métrica se puede usar ya que hay un buen balance de cada clase en el dataset.\n",
    "- **Kappa:** Especifica la mejora del modelo con respecto a un modelo (Baseline) que \"adivina\" la clase (diagnóstico) de acuerdo a la frecuencia de cada clase (PD o No-PD).\n",
    "- **Especificidad:** Proporción de pacientes clasificados correctamente como no-PD, de todas las personas sin PD.\n",
    "- **Precisión:** Dice la proporción de pacientes clasificados correctamente con PD, del total de pacientes clasificados con PD.\n",
    "- **Recall:** Proporción de pacientes clasificados correctamente con PD, del total pacientes diagnosticados con PD.\n",
    "- **f1-Score:** Es la media armónica entre la precisión y el recall, lo cual entrega una métrica que permite evaluar P y R. La media armónica puede representar mejor al recall y la preción cuando existe mucha diferencia entre ambos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_precision(y_test,y_pred):\n",
    "    return metrics.precision_score(y_test,y_pred,pos_label='Positivo')\n",
    "\n",
    "def wrap_recall(y_test,y_pred):\n",
    "    return metrics.recall_score(y_test,y_pred,pos_label='Positivo')\n",
    "\n",
    "def wrap_f1(y_test,y_pred):\n",
    "    return metrics.f1_score(y_test,y_pred,pos_label='Positivo')\n",
    "\n",
    "def wrap_kappa(y_test,y_pred):\n",
    "    return metrics.cohen_kappa_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.7266081871345029\n",
      "Kappa_Score:  0.4534192756292204\n",
      "\n",
      "Precisión:  0.748088023088023\n",
      "Recall:  0.6888888888888889\n",
      "F1_score:  0.7054295051353876\n"
     ]
    }
   ],
   "source": [
    "scores = {\n",
    "    'acc':'accuracy', \n",
    "    'kappa' : metrics.make_scorer(wrap_kappa),\n",
    "    'precision' : metrics.make_scorer(wrap_precision),\n",
    "    'recall' : metrics.make_scorer(wrap_recall),\n",
    "    'f1' : metrics.make_scorer(wrap_f1)\n",
    "}\n",
    "\n",
    "cv_scores = cross_validate(estimator=ada, X=x,y=y, cv=10, return_train_score=False, scoring=scores)\n",
    "\n",
    "print('Exactitud: ', np.average(cv_scores['test_acc']))\n",
    "print('Kappa_Score: ', np.average(cv_scores['test_kappa']))\n",
    "print()\n",
    "print('Precisión: ', np.average(cv_scores['test_precision']))\n",
    "print('Recall: ', np.average(cv_scores['test_recall']))\n",
    "print('F1_score: ', np.average(cv_scores['test_f1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretación de métricas:\n",
    "\n",
    "La exactitud del modelo AdaBoost y la regresión logistica son muy similares, pero este modelo tiene una mejor sensibilidad que la regresión, lo cual indica que es mejor para diferenciar a los pacientes con PD de los pacientes sanos, a pesar de que sacrifique un poco la precisión.\n",
    "\n",
    "Por lo anterior, el modelo de AdaBoost es la primera opción para diagnósticar pacientes de PD de los modelo explorados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
